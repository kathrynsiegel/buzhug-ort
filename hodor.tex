\documentclass[11pt, oneside]{article}

\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{parskip} % for spaces between paragraphs
\usepackage[top=1.5in, bottom=1.5in, left=1.5in, right=1.5in]{geometry} % for custom margin sizes
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{pslatex}
\usepackage{enumerate}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{color}
\usepackage[margin=.25in]{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{verbatim}
\usepackage{algorithmicx}

% Algorithms
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\newcommand*\Let[2]{\State #1 $\gets$ #2}
\algrenewcommand\algorithmicrequire{\textbf{Precondition:}}
\algrenewcommand\algorithmicensure{\textbf{Postcondition:}}

\usetikzlibrary{automata,topaths}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\newcommand{\ms}{\textit}
\newtheorem*{lemma}{Lemma}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{mymauve},     % string literal style
}


\title{HODOR: HODOR On-Disk Orthogonal Range-trees}

\author{Stephanie Wang (swang93@mit.edu)\\
Bennett Cyphers (bcyphers@mit.edu)\\
Katie Siegel (ksiegel@mit.edu)\\[2ex]
6.851 Final Report}

\date{\today}

\begin{document}

\maketitle

\vfill

\begin{abstract}

    HODOR hodor hodor, HODOR hodor hodor hodor hodor. HODOR hodor HODOR
    \textit{HODOR HODOR} hodor hodor hodor HODOR. HODOR, "hodor hodor," hodor
    hodor HODOR hodor hodor. HODOR hodor hodor HODOR hodor HODOR. \\

    GitHub: https://github.com/kathrynsiegel/buzhug-ort

\end{abstract}

\clearpage

\section{Introduction}

Web applications today often require batch queries on large datasets in two or
more dimensions. Databases typically support efficient range querying on one
primary key at a time. Multi-dimensional range queries, however, are expensive,
and common implementations require $O(n)$ time. 

As we saw in class, orthogonal range trees (ORTs) can achieve range queries on $d$
dimensions in $O(\log^{d} n + k)$ time, where $k$ is the size of the result set
\cite{lecture}. These trees have been implemented in memory with success,
including as an extension to the popular database Redis \cite{redis}. In-memory
databases are useful for smaller datasets, or for companies with enough
resources to operate expansive data centers. However, for data sets
which are too large to fit in main memory, magnetic hard disks remain the most
economical long-term storage option. On-disk data structures present a unique
set of challenges requiring a unique solution. To this end, we designed HODOR,
an on-disk Python implementation of orthogonal range-trees. 

The main obstacle to an on-disk implementation of orthogonal range trees is the
added overhead in disk access time. Therefore, in this paper, we explore
different methods of optimizing disk I/O accesses, in terms of disk read
frequency and overall query time. First, we present our overall design, and
specific modifications we made to the standard ORT structure. Second, we
describe our serialization protocols for the data structure. Third, we analyze
each query in terms of both total disk accesses and a new metric,
\textit{back seeks}, which we introduce here. We describe how to achieve more
efficient runtime by eliminating back seeks from our data structure's
query function. Finally, we present experimental test data, and discuss how our
findings from this project may contribute to future work.

\section{Design}

In this section, we detail the design of HODOR, and describe the decisions we
made in the process.

\subsection{Goals}

The primary goal of HODOR is to allow efficient range queries of very large
datasets in an arbitrary number of dimensions. We designed the structure to
perform on machines with a limited amount of memory and a large amount of
storage on a relatively slow hard disk. As such, we wanted to minimize the
time spent reading data from disk, but were generally unconcerned with
in-memory comparison operations. We optimized for this in two ways: first, by
minimizing total disk reads, and second, by chaining consecutive disk accesses
so that they can be executed as efficiently as possible. 

HODOR requires a relatively long time to construct its tree and serialize it to
disk, so the results presented in this paper are for queries on static trees
only. In addition, there are well-documented techniques for augmenting range
trees, such as fractional cascading, which can speed up queries by a logarithmic
factor. However, the goal of this project was more to determine whether we could
achieve the same range query bounds on disk as in memory, rather than to build
the fastest structure possible.

\subsection{Range B-Trees}

The standard data structures used for implementing many table-style databases
are the B Tree, and the modified version, the B+ Tree. As a quick overview, a B Tree is a
search tree with a branching factor of $B$, i.e., each node points to at most
$B$ children. A B+ Tree is an extension of the B Tree in which all data is stored at the
leaves of the tree, and each leaf has a pointer to its immediate predecessor
leaf, \ms{prev}. The logic behind the B Tree's design is that, since the act of
loading children from disk into memory is often the bottleneck on database
search performance, each node should load as many children as it can into memory
at once. $B$ can then be tweaked to optimize for cache sizes on different machines.
The predecessor pointers in a B+ tree allow easy range queries in one
dimension: once we find the leaf with the maximum value in the range, we can
walk backward along the predecessor leaves until we reach the one containing the
minimum value, and return all leaves touched on the walk.

The orthogonal range tree is a structure covered in 6.851 which allows
$O(\log^d n + k)$ range queries on $d$ dimensions. For HODOR, we extend the B+
Tree structure with orthogonal, recursive linked trees to create B+ Orthogonal
Range Trees (BORTs). Each node $n$ in a BORT has a dimension $d$, a set of $B$
child pointers sorted in $d$, and a pointer to another BORT containing all of
the data points contained in $n$'s subtree, known as $n$'s \textit{linked
tree}. When $n$ is loaded into memory, it brings with it all $B$ child pointers
and one link pointer. Therefore, a search on $n$ data points indexed in $d$
dimensions touches $O(log^d_B n)$ nodes, which requires $O(log^d_B n)$ disk
accesses.  However, as we will describe below, not all disk accesses are equal,
and we can achieve better in-practice running times by laying out serialized
nodes intelligently on disk.

\subsection{Node serialization}

In order to store range trees on disk, we require an efficient method to
serialize and deserialize the data structure. In HODOR, we represent a Python
\ms{RangeTree} instance as a list of serialized nodes, which may be instances of
\ms{RangeNode} or \ms{RangeLeaf}. This list is stored in a \textit{tree file}, which
can be written to and read by a \ms{Serializer} class. 

% Talk about how serializer does not actually append nodes, but puts them on top
% of a stack, then pops everything off of the stack in the dumps() method?
During preprocessing, when building the tree from a set of datapoints,
\ms{Serializer} is initialized in write mode to build the tree file. In write
mode, \ms{Serializer} exposes a \ms{dumps(node)} method that accepts a
node instance, serializes the node, and adds it to the top of a \textit{node stack},
a temporary data structure which holds serialized nodes before the whole tree is
flushed to disk. This method also assigns the node a pointer into the tree file,
equal to the number of nodes which have already been serialized. As the size of
the node stack is likely to exceed the total amount of memory available, the
stack is stored on disk in a temporary file while building the tree. 

Once every node has been serialized and placed on the stack, we call
\ms{Serializer.flush()}. This method writes the serialized nodes to disk in the
reverse order that they were created with \ms{dumps}, by popping each element
off of the node stack and appending it to a tree file. Once tree serialization
is complete, the temporary stack file can be deleted. From this point onwards,
\ms{Serializer} is in read mode, and can only be used to read from the tree.

In read mode, \ms{Serializer.loads(pointer)} can be called to deserialize a
single node into a Python node instance, given its pointer into the tree file.
So, to give a parent access to its child, we simply store the child's tree file
pointer as an attribute of the parent. \ms{loads} is implemented by seeking to
the pointer in the tree file and reading out a single node's worth of bytes.

% maybe some of this should go into Implementation details maybe something
% about cPickle vs struct
The seeking method varies by serializer. In HODOR, we test two main node
serialization methods. The first is to use a delimiting character, such as a
newline, between nodes. The second is to pack nodes into fixed-length strings,
called \textit{blocks}. 

Delimited strings are convenient because they support
arbitrarily sized datapoint values. However, seeks may be costly in performance
even with Python optimizations like line iterator or linecache features
[CITATION]. 

On the other hand, when nodes are stored as blocks, a node's exact byte
position can be calculated from its file pointer and seeked directly, yielding
a lower performance cost when reading disk. However, fixed-length blocks may
limit the type and size of data that can be stored. This can be solved by
storing the data points themselves as delimited strings in a separate
\textit{database file} and storing pointers to this data in the leaves of the
ORT. A range query can return a set of pointers into the database file that can
be sorted and used to access the actual data sequentially from the file. This
method requires one extra disk read for each of the $k$ datapoints in the
result set, but no extra back seeks.

% stats on block serializer vs line serializer here?

\subsection{Tree serialization}

Tree serialization is executed while preprocessing the datapoints into a tree,
so that the order of nodes in the tree file is the same as the order in which
HODOR preprocesses them. The tree is built recursively, from the bottom up.
HODOR starts with a set of children. If these are leaves, then HODOR sorts them
in the primary dimension of the current tree. If the full set of leaves is too
large to fit in memory, the algorithm can use funnel sort to arrange them on
disk [CITATION]. Next, HODOR partitions the children into clusters of at most $B$ items.
For each of these clusters, HODOR creates a parent node and recurses to build
the parent's linked tree in the next dimension, if any dimensions remain. If
there is only one parent, then the parent is the root of the tree, and HODOR is
done.  Otherwise, HODOR recurses on the parents.

% TODO: fix formatting
\begin{figure}[h]
    \centering
    \vspace{0.5in}
    \includegraphics[width=0.8\textwidth]{fig1.eps}
    \caption{Awesome Image}
    \vspace{0.5in}
\end{figure}

% move fig 1 here
HODOR serializes the nodes in the same order that they are created. In the
recursion for a set of children, all children are serialized first, followed by
the linked subtree for each parent node, followed by the node itself. Each
child is serialized before its parent, and each parent is serialized
immediately after its linked subtree in the next dimension. This forms a series
of levels \cite{seinfeld} for each tree [FIGURE 1]. Consider a BORT $t$. Each
node $n$ in $t$ falls in the same level as all of $n$'s siblings. The entirety
of $n$'s linked subtree, which is indexed in the next dimension, also falls in
this same level of $t$. All of $n$'s children and their linked subtrees fall in
the level below $n$'s, and $n$'s parent falls in the level above. 

All the leaves of the tree in the first dimension are in that tree's lowest
level, and are therefore serialized first. The root of the same tree is in the
tree's highest level, and is therefore serialized last. The leaves and root of
each linked subtree follow the same pattern. 

\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth]{fig2.eps}
    \caption{Awesome Image}
    \vspace{0.5in}
\end{figure}

% move fig 2 here
Once we finish building the tree, we flush the nodes in the stack to the tree file on disk
in reverse order of serialization, as described above. This way, each node will
fall after all of its ancestors [FIGURE 2]. In the final disk layout, the root
of the tree in the first dimension is the first node in the file, and the leaves
of the same tree occur last in the file. This layout allows us to always read
forward through the file as we traverse downwards from any node, as we do in a
range query. Since each node falls immediately before its linked subtree in the
next dimension, we also read forward through the file when traversing from one
dimension to the next. All of the siblings in one level were originally pushed
onto the stack in order, so when they are popped from the stack, they will be
written in reverse order. Then, within each level, the maximum-valued sibling
now comes first and the minimum-valued sibling now comes last. 

\section{Analysis}

In this section, we analyze the performance of queries in HODOR with respect to
disk reads. A disk read is needed to load any object not yet in memory.
Therefore, any time an algorithm accesses a node not previously seen, the
algorithm must do one disk read.

In our analysis, we will focus on measuring disk reads in two categories.
Assuming we are reading blocks from one continuous file on disk,
\textit{forward seeks} are defined as reads from a location after the current
file pointer. \textit{Back seeks} are reads from a location before the current
pointer. In our disk-memory model, forward seeks are, in general, much faster
than back seeks. When accessing file blocks in sequential order, the blocks can
be loaded into memory at speeds approaching the disk's maximum read speed.
However, if a file block at position $i-1$ is accessed immediately after the
file block at $i$, the disk must make a complete revolution before block $i-1$
can be loaded. On a typical drive spinning at 7200 RPM, this revolution takes
over 8 milliseconds.

In addition to minimizing total disk reads, we tried to minimize back seeks
wherever possible when designing HODOR. We will analyze our data structures in
terms of both total reads and total back seeks in the sections below.

\subsection{Disk read analysis}

We will now examine the complexity of a search on a fully formed BORT, in terms
of total disk reads. The algorithm for performing a range query on a (non-leaf)
node is as follows, in pseudocode.

\begin{algorithm}[H]
    \caption{Recursively find all elements in a multidimensional range}
    \begin{algorithmic}[1]
        \Require{\nod\textsc{Ranges} is a dictionary of (start, end) range
            tuples indexed by dimension, $n$ is a node, and $d$ is an integer
            representation of the dimension $n$ is indexed by. 0 is the last
            dimension. \\

            }
        \Statex
        \Function{RangeQuery}{Ranges, $n$, $d$}
            \Let{$start, end$}{Ranges[$d$]}
            \If{$d = 0$}
                \Let{$pred$}{\Call{$n$.Predecessor}{$end$}}
                \State \Return\Call{GetRange}{$pred$, $start$}
            \EndIf
            
            \State
            \Let{$r$}{Null}
            \Let{$c_L$}{\Call{GetChildContaining}{$start$}}
            \Let{$c_R$}{\Call{GetChildContaining}{$end$}}
            \State \Call{Load}{$c_R$}
            \State

            \ForAll{$c_i$ in \Call{ChildrenInRange}{$n$, $end$,
                    $start$}}
                \State \Call{Load}{$c_i$}
                \Let{$l_i$}{\Call{LinkedTree}{$c_i$}}\Comment{Get the child's linked
                    subtree}
                \Let{$r$}{$r$ + \Call{RangeQuery}{\textsc{Ranges}, $l_i$, $d-1$}}
            \EndFor

            \State
            \State \Call{Load}{$c_L$}
            
            \Let{$r$}{$r$ + \Call{RangeQuery}{$c_R$}}
            \Let{$r$}{$r$ + \Call{RangeQuery}{$c_L$}}

            \State \Return{$r$}
        \EndFunction
    \end{algorithmic}
    \hspace{1cm}
    \begin{algorithmic}[1]
        \Require{$n$ is a leaf in the last dimension and has data representing
        $B$ elements of the tree. $start$ is the startpoint of the queried
        interval in the last dimension.}
        \Function{GetRange}{$n$, $start$}
            \Let{$data$}{data at $n$ that is greater than or equal to $start$}

            \If{$n.min \ge start$}
            \Let{$data$}{$data$ + \Call{GetRange}{$n.prev()$, $start$}} \Comment{Load the leaf previous to $n$}
            \EndIf

            \State \Return{$data$}
        \EndFunction
    \end{algorithmic}
\end{algorithm}

In the base case, the node is in the last dimension, and the function is reduced
to a \textsc{GetRange} call. \textsc{GetRange} is a function which returns all
leaves in the range in this node's subtree. It is accomplished by searching for
the leaf containing \ms{end}, and walking backwards along the link's \ms{prev}
pointers until the leaf containing the minimum value is found. This operation
takes $O(\log_B n + \frac{k}{B})$ reads, since each leaf contains $B$ elements.

% TODO: rewrite
In total, each recursive call on a node involves $O(B)$ disk reads to load each of its $B$ children. Using an analysis similar to lecture 3, for a tree in one dimension, this can happen for as many as $O(\log_B n)$ nodes [CITATION]. , and
recurses on $(O(\frac{n}{B})$ elements in its own dimension and $O(n)$ elements
in the next dimension; the base case involves a maximum of $O(\log_B n +
\frac{k}{B})$ reads. Therefore, running the entire algorithm from the root node
of a BORT makes $O(\log_B^d n + k)$ reads from the disk. In the sections below,
we will analyze how we can bound the \textit{types} of disk reads we have to
make.

% TODO: algorithm format
The logic at the leaf level is not shown in the pseudocode. Once
\ms{range\_query} is called on a leaf, the leaf will either return some subset
of its data, which is already loaded, or recurse on a linked leaf in the next
dimension, requiring one disk read per dimension. 

\subsection{Back seek analysis}

The efficiency of tree serialization in terms of back seeks depends on the path
taken by a range query. We want to order the node accesses during a range query
so that we do as many consecutive forward seeks as possible, while minimizing
back seeks. Here we analyze the worst-case back seek count for the given range
query algorithm by counting the number of back seeks needed for each recursion,
using figure 1 as a reference for the order that we access nodes. 

As discussed above, the nodes are structured into recursive levels on disk,
where each level contains a node, all of its siblings, and its linked subtree
in the next dimension. The number of back seeks we do during each recursion
depends on the order in which nodes of the same level are accessed and the
order in which the levels themselves are accessed. Each level is sorted in
reverse order, so if a node is accessed after its left sibling, it will cost
one back seek. For each tree, the levels themselves are sorted in order from
highest to lowest, so if an ancestor is accessed after the node itself, it will
also cost one back seek. 

The range query recursion starts at the root of a subtree, illustrated by node
0 in figure 1. Because a node and all of its siblings lie in the same level,
when the range query accesses the root's children, all work is done in the same
level. This is the level after the root's, or level 1 in figure 1. Each level
is sorted in reverse order in the file, so if the range query accesses the
children from max to min (right to left), then no back seeks are needed to load
the root's children. Because the range query always traverses downwards, we
never return to the root's level (level 2) once we access the children's level
(level 1). 

We analyze the back seeks needed for a recursive call on a child by examining
the node and level access order. There are two possible types of recursive
calls: either we recurse on the child's linked node when the child is
completely contained in the queried interval, or we recurse on the child itself
when the child contains either \ms{start} or \ms{end}.

The first case can be illustrated by node 2. Suppose node 2's entire range is
contained in the queried interval, so we recurse on its linked node, node 5.
Note that the linked subtree at node 5 falls in the same level, level 1, as
node 2.  Therefore, the recursive call on node 5 stays within level 1. Also,
since a node occurs immediately before its linked subtree in the disk layout,
we can make the recursive call to node 5 directly after loading node 2 in order
to avoid back seeks within the same level. Thus, a recursive call of the first
case costs nothing in back seeks.

The second case can be illustrated by node 1, in level 1. Suppose that node 1
contains \ms{start}, so we recurse on node 1 and load its children in 0.
According to the level structure of the disk layout, level 1 comes before level
0, so we can load node 1's children by seeking forward from level 1 to level 0.
However, if the range query ever has to access level 1 again, a back seek will
be needed to return from level 0 or a level even further down the tree. This
happens when the recursive call on a node is followed by a recursive call on
one of that node's siblings, which lie in the same level. For example, the
recursive call on node 1 will traverse down the tree, ending at some level past
level 1 in the tree file. If we then do a recursive call on one of the nodes
2-4, it will cost one back seek to return back to level 1. In other words,
during the recursion on node 0, if more than one recursive call of the second
case is made, then every call except the last will contribute one back seek. \\


\begin{lemma}
    According to the given algorithm, there will be at most $O(\log_B^{d-1}n)$
    many back seeks, where $d$ is the number of dimensions and $B$ is the
    branching factor. 
\end{lemma}
\begin{proof}
    As we noted above, during each recursion step, any recursive call of the
    second case that is followed by another recursive call in the same step
    contributes one back seek. A recursive call of the second case can only be
    called on a child whose range is not completely contained within the
    queried interval, and whose range contains the \ms{start} or \ms{end}
    point. So, for each recursive step, there will be at most two recursive
    calls of the second case. If there is zero or one, then the recursive step
    does not contribute any back seeks. If there are two, the recursive step
    contributes exactly one back seek.

    \begin{figure}[h!]
        \centering
        \vspace{0.5in}
        \includegraphics[width=0.6\textwidth]{fig3.eps}
        \caption{Awesome Image}
        \vspace{0.5in}
    \end{figure}

    For a range query on a tree, there is at most one recursive step that
    requires making two such recursive calls. This happens when the root node
    of the recursion is the least common ancestor (\ms{lca}) of the predecessor
    of \ms{start} and the successor of \ms{end} [CITATION lecture 3]. This is
    illustrated by node 2, the \ms{lca} of nodes 5 and 6, in figure 3. By
    definition, \ms{lca} has one child (node 3) containing \ms{start} and a
    different child (node 4) containing \ms{end}, each requiring one recursive
    call. Each node that is an ancestor of \ms{lca} (nodes 0 and 1) covers the range
    of \ms{lca}'s range, so it has a child that contains both \ms{start} and
    \ms{end}. Only one recursive call on this child is needed. Each node that
    is a descendant of \ms{lca} (nodes 3 and 4) can have at most one child that
    contains either \ms{start} or \ms{end}, not both, since \ms{start} and
    \ms{end} were contained in different children of \ms{lca}. 

    Recursing on an \ms{lca} can happen at most once during a range query on a
    linked tree. Therefore, the total number of back seeks performed by a range
    query is bounded above by the number of distinct linked trees that are
    queried. Using a similar analysis to the one given in lecture 3, this is
    $O(1)$ for 1 dimension, since there is only one tree. It is $O(\log_B n)$
    for 2 dimensions, since we recurse on at most $O(\log_B n)$ linked subtrees
    in the second dimension. Recursing on $d$, we get $O(\log_B^{d-1}n)$ for
    $d$ dimensions.

\end{proof}

\subsection{Minimizing back seeks}

The given range query algorithm requires back seeks because of accesses to a
level that we have already previously traversed past. We can eliminate these
accesses by ensuring that by the time we traverse downward from some node, all
work that will ever be done in that node's level has already finished. The work
done on that node's level is the work involving that node, its children, and
its linked subtree in the next dimension. Here, we propose a modified algorithm
that accomplishes this and analyze its complexity in back seeks.

Like the naive algorithm, the modified algorithm starts at the root of the tree
in the first dimension. However, rather than recursing on one node at a time,
the modified algorithm recurses on a set of nodes. Similar to before, the
algorithm determines which out of the current set of nodes cover ranges that
fall completely within the queried interval. For these nodes, the algorithm
makes a recursive call to the linked nodes, as in the naive algorithm. However,
for the second case of the recursive call, when a node in the current set has a
range containing \ms{start} or \ms{end}, the algorithm does not recurse
immediately on that node's children. Instead, the algorithm collects the
children of these nodes in the current set, and recurses on the union of the
children.

% prove that the current set of nodes is all in the same level, so that we can
% guarantee no back seeks between nodes in the current set
To show that the modified algorithm does not require any back seeks, we first
prove that for any recursive call, the nodes in the current set are all in the
same level. Then, if we do our work for each node in order of max to min, the
order in which the siblings are laid out on disk, we will avoid all back seeks
between nodes in the current set. \\

\begin{lemma}
    For any recursive call during the modified algorithm, the set of nodes that
    is recursed upon falls in the same level. 
\end{lemma}
\begin{proof}
    We can prove this by showing that it is an invariant. Assume that the nodes
    in the set for the current recursion are all in the same level. From here,
    we may recurse on the node's linked node or we may recurse on the combined
    children of some number of nodes in the current set. The linked node is a
    set of one. Each child of a parent falls in the level immediately after the
    parent's level, so the combined children of the current set all fall within
    the same level. In either case, any recursive call that we make will be on
    a set of nodes that are all in the same level. We begin the entire range
    query from a set of one, the root of the tree in the first dimension.
    Therefore, any recursive call that we make will be upon a set of nodes in
    the same level. 
\end{proof}

% prove that we never need to come back to this level
Since we do not require any back seeks between nodes in the current set, the
only other possible source of back seeks is from the recursive calls. We know
from the lemma that the current set of nodes for a recursion is in the same
level. The case when we do a recursive call on one of the nodes' linked
subtrees is then the same as in the naive algorithm; these do not cost any back
seeks since we remain in the same level and can do all the recursive calls in
order of disk layout. 

The other case is when we do a recursive call on the union of some nodes'
children. In this case, we are accessing the level after the current set's
level. If we do this recursive call after recursing on the linked subtrees, we
will never return to the current nodes' level, and will therefore not need any
back seeks following this recursive call. Thus, each recursion, and therefore
the modified algorithm as a whole, does not require any back seeks.

\subsection{Results}

% stats
\begin{figure}[h]
\centering
\begin{tikzpicture}
	\begin{loglogaxis}[
		xlabel=Data Size (Total Entries),ylabel=Number of Seeks]

	\addplot[color=blue,mark=*] coordinates {
		(1024,280524)
		(4096,264056)
		(16384,208401)
		(65536,176031)
		(262144,164698)
        (1048576,156474)
	};
	\addplot[color=red,mark=*] coordinates {
		(1024,16250)
		(4096,4061)
		(16384,1497)
		(65536,1101)
		(262144,1000)
        (1048576,558)
	};
	\legend{$Forward\ seeks$,$Backward\ seeks$}
	\end{loglogaxis}%
\end{tikzpicture}%
\caption{
    The number of forwards and backwards seeks invoked by range queries varies
    with the size of the data set in the orthogonal range tree. While
    backwards seeks are far more costly than forward seeks, they are far
    fewer in number, and the number of back seeks as a fraction of total seeks
    decreases exponentially as the set of data points grows.
}
\label{fig:figure2}
\end{figure}

\section{Conclusion}

% note about our model: we've dealt with things in terms of time and space
% before, and we dealt with disk accesses in cache-obliviousness, but this is
% cool ... and stuff
    
% not all reads are created equal
We found in our results that not all data accesses are equal in performance.
Back seeks, or seeks that require reading at a point earlier than the current
file position, require significantly more time than forward seeks. Thus, when
implementing on-disk data structures, it is critical to consider the number of
back seeks required during each operation. 

% it is possible to eliminate back seeks
While back seeks in Hodor took a significantly longer time than forward seeks,
we did find that it was possible to eliminate back seeks by adjusting the tree
serialization order and the range query algorithm so that they could work in
unison. With a naive recursive range query implementation, it is possible to
achieve $O(\log_B^d n)$ many back seeks by using a similarly recursive disk
layout. With the same disk layout, it is possible to achieve no back seeks at
all by adjusting the range query implementation to better fit the levels
structure in the disk layout. Therefore, our work in Hodor shows that for
orthogonal range trees, it is possible to eliminate back seeks by adjusting the
disk layout and the implementation of the range tree operations to account for
each other. 

% back seek model can be applied to other data structures for a large dataset 
Orthogonal range-trees can in theory achieve significant speedup over a
traditional database, making it desirable to implement them efficiently
on-disk. Still, they are just one of many data structures that would be useful
for representing a dataset too large for memory [Example?]. We believe that the
back seek model used to analyze Hodor's performance would be effective for
analysis of other such on-disk data structure implementations. We showed in
Hodor that while back seeks are costly in performance, they are also avoidable
with an operation-aware serialization order and serialization-aware operations.
Thus, we hope that the Hodor results may be used as a basis for optimizing
future implementations of on-disk data structures. 

\begin{figure}[b]
    GitHub: https://github.com/kathrynsiegel/buzhug-ort
\end{figure}

\newpage

\begin{thebibliography}{1}
    
    \bibitem{lecture} Demaine, Erik. ``Lecture 3,'' February 23, 2012.  MIT: \\
        http://courses.csail.mit.edu/6.851/spring14/scribe/lec3.pdf, n.d. PDF.

    \bibitem{redis} Kaler, Tim, and Oscar Moll. ``Spatial Data Structures -
        Performance Comparision.'' N.p.: \\
        http://tfk.mit.edu/pdf/2drangesearch\_datastructures.pdf, 25 May 2012.
        PDF.

    \bibitem{seinfeld} Cherones, Tom. ``The Pony Remark.'' \textit{Seinfeld.}
        NBC. 30 January 1991. Television.

\end{thebibliography}
\end{document}
